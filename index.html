<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>C-MCTD</title>
  <link rel="icon" type="image/x-icon" href="static/images/mctd.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      }
    };
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Compositional Monte Carlo Tree Diffusion for Extendable Planning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://jaesikyoon.com" target="_blank">Jaesik Yoon</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                Hyeonseo Cho<sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://mlml.kaist.ac.kr/sungjinahn" target="_blank">Sungjin Ahn</a><sup>1,3</sup>
              </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>KAIST, <sup>2</sup>SAP, <sup>3</sup>NYU
                  <br>NeurIPS 2025, <span style="color: #8FBC8F; font-style: italic;">Spotlight (top 3.2% of submissions)</span>
                </span>
                </span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2510.21361" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2510.21361" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                  </span>

                  <!-- MCTD Page link -->
                  <span class="link-block">
                    <a href="https://jaesikyoon.com/mctd-page/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-link"></i>
                    </span>
                    <span>MCTD Page</span>
                    </a>
                  </span>

        </div>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="banner-videos" style="display: flex; gap: 16px; justify-content: center; align-items: center;">
        <img src="static/images/c_mctd_maze_illustration.png" alt="Key Result" style="max-width: 100%; height: auto;">
      </div>
      <br>
      <h2 class="subtitle has-text-centered">
        Monte Carlo Tree Diffusion (MCTD) effectively tackles complex planning tasks by combining diffusion models with structured tree search.
        However, its core limitation is the inability to generate these high-quality plans for longer trajectories than seen during training.
        We propose Compositional MCTD (C-MCTD), a framework that overcomes this by generating a globally coherent plan from smaller, individually generated trajectory segments.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured tree search to enable effective trajectory exploration through stepwise reasoning. However, MCTD remains fundamentally limited by training trajectory lengths. While periodic replanning allows plan concatenation for longer plan generation, the planning process remains locally confined, as MCTD searches within individual trajectories without access to global context. We propose Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates planning from individual trajectory optimization to reasoning over complete plan compositions. C-MCTD introduces three complementary components: (1) Online Composer, which performs globally-aware planning by searching across entire plan compositions; (2) Distributed Composer, which reduces search complexity through parallel exploration from multiple starting points; and (3) Preplan Composer, which accelerates inference by leveraging cached plan graphs.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- MCTD -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Preliminary: Monte Carlo Tree Diffusion (MCTD)</h2>
        <div class="content has-text-justified">
          <p>
            Our work builds upon <strong><a href="https://jaesikyoon.com/mctd-page/" target="_blank" style="text-decoration: underline;">Monte Carlo Tree Diffusion (MCTD)</a></strong>, a framework that reframes trajectory planning as a tree search problem by integrating the generative power of diffusion models with the structured search capabilities of MCTS.
            The framework is built on three key concepts:
          </p>
          <p>
            <strong>1. Denoising as Tree Rollout</strong><br>
            Unlike conventional MCTS which performs rollouts at the state level, MCTD operates on <strong>subplans</strong>—segments of the full trajectory. A complete trajectory $\mathbf{x}$ is partitioned into a sequence $[\mathbf{x}_1, \dots, \mathbf{x}_S]$.
            By generating these semi-autoregressively, MCTD performs intermediate evaluations akin to MCTS rollouts.
            This approach effectively reduces the search tree's depth while preserving the global coherence of diffusion models.
            $$
              \begin{align}
                p(\mathbf{x}) \approx \prod_{s=1}^S p(\mathbf{x}_s|\mathbf{x}_{1:s-1})
              \end{align}
            $$
          </p>
          <p>
              <strong>2. Guidance Levels as Meta-Actions</strong><br>
              To manage the exploration-exploitation trade-off, MCTD introduces <strong>guidance levels</strong> as meta-actions. For each subplan $\mathbf{x}_s$, a discrete control mode—such as $\text{GUIDE}$ or $\text{NO_GUIDE}$—is selected.
              By dynamically controlling the guidance level $g_s$ for each subplan, MCTD can balance exploration and exploitation within a single, unified denoising process.
              $$
                \begin{align}
                  p(\mathbf{x}|\mathbf{g}) \approx \prod_{s=1}^S p(\mathbf{x}_s|\mathbf{x}_{1:s-1}, g_s)
                \end{align}
              $$
          </p>
          <p>
              <strong>3. Jumpy Denoising as Fast Simulation</strong><br>
              For efficient simulation, MCTD utilizes a fast, <strong>jumpy denoising</strong> process based on the Denoising Diffusion Implicit Model (DDIM) (<a href="https://arxiv.org/abs/2010.02502" target="_blank" style="text-decoration: underline;">Song et al., 2020</a>).
              This technique significantly accelerates the search process while maintaining high-quality trajectory generation for evaluation.
              $$
                \begin{align}
                  \tilde{\mathbf{x}}_{s+1:S} \sim p(\mathbf{x}_{s+1:S}|\mathbf{x}_{1:s}, \mathbf{g})
                \end{align}
              $$
          </p>
          <p>
              <strong>Four Canonical Steps of MCTD</strong><br>
              MCTD implements these components through a modified MCTS procedure. The four canonical steps—Selection, Expansion, Simulation, and Backpropagation—are adapted to handle subplan generation within this diffusion-based planning process.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Fast-MCTD -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Fast-MCTD: Fast Monte Carlo Tree Diffusion</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we addressed the efficiency issue of MCTD in the two aspects: <strong>Between-rollout inefficiency</strong> and <strong>Within-rollout inefficiency</strong>.
            The inefficiency between rollout is from the sequential statistics updates of MCTS, limiting parallelism, we addressed this by re-designing the MCTD tree search to be parallelizable with Parallel MCTD (P-MCTD).
            The inefficiency within rollout is from the iterative denoising process of diffusion model, which is computationally intensive. To optimize the within-rollout inefficiency, we proposed the higher-level planning, Sparse MCTD (S-MCTD).
            <br>
            <br>
          </p>
        </div>
        <h3 class="title is-4">Parallel MCTD</h3>
        <div class="content has-text-justified">
          <p>
            <div style="text-align: center;">
              <img src="static/images/pmctd_overview.png" alt="PMCTD Overview" style="width: 90%; height: auto;">
            </div>
            <br>
            To design a parallelized version of MCTD, we apply three techniques: Delayed Tree Update, Redundancy-Aware Selection, and Parallel Denoising on Expansion and Simulation.
            <strong>Delayed Tree Update</strong> postpones tree updates until $K$ rollouts complete, enabling parallel processing of multiple rollouts. While this causes inefficiency from operating on outdated tree statistics, we empirically find this overhead negligible compared to denoising costs. However, delayed updates alone are insufficient for efficient parallelization due to potential duplicate rollouts.
            <strong>Redundancy-Aware Selection</strong> addresses duplicate rollouts by redesigning the node selection policy to account for concurrent rollouts, inspired by <a href="https://arxiv.org/abs/1810.11755" target="_blank" style="color: #00A1D6; text-decoration: none;">Liu et al., 2018</a> and <a href="https://dke.maastrichtuniversity.nl/m.winands/documents/multithreadedMCTS2.pdf" target="_blank" style="color: #00A1D6; text-decoration: none;">Chaslot et al., 2008</a>:
            $$
              \pi(i) = \arg\max_{j\in\mathcal{C}(i)}\left(V_j + \beta \sqrt{ \frac{\log (N_i + \hat{N}_i \cdot w)}{N_j + \hat{N}_j \cdot w}}\right),
            $$
            where $\pi(i)$ denotes the node selection policy from node $i$, $\mathcal{C}(i)$ is the child node set, and $V_{i}$, $N_{i}$ represent estimated value and visitation count respectively. The hyperparameter $w$ balances exploration-exploitation for parallel search: $w=0$ reduces to standard MCTD selection, while higher values penalize already-selected nodes in the current batch, encouraging exploration of different tree regions.
            Additionally, we designed to process the selection sequentially to reduce the possibility of the duplicate rollout.
            <strong>Parallel Denoising on Expansion and Simulation</strong> optimizes computational overhead. Unlike standard MCTS, MCTD incurs substantial expansion overhead due to denoising processes. We parallelize denoising by batching rollouts—since subplan lengths vary across rollouts, subplans are zero-padded and packed into single batches, enabling high-throughput parallel GPU execution. The table below shows operation times for each MCTD step on PointMaze Giant tasks.
            <div style="width: 100%; display: flex; justify-content: center; margin: 1em 0;">
              <table style="border-collapse: collapse; min-width: 320px; max-width: 400px; font-size: 1.1em;">
                <thead>
                  <tr>
                    <th style="border-bottom: 2px solid #222; border-top: 2px solid #222; text-align: left; padding: 6px 12px;">MCTD Step</th>
                    <th style="border-bottom: 2px solid #222; border-top: 2px solid #222; text-align: left; padding: 6px 12px;">Time (sec.)</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td style="border-bottom: 1px solid #222; padding: 6px 12px;">Selection</td>
                    <td style="border-bottom: 1px solid #222; padding: 6px 12px;">3e-4 (0.05%)</td>
                  </tr>
                  <tr>
                    <td style="border-bottom: 1px solid #222; padding: 6px 12px;">Expansion</td>
                    <td style="border-bottom: 1px solid #222; padding: 6px 12px;"><strong>0.393 (70.9%)</strong></td>
                  </tr>
                  <tr>
                    <td style="border-bottom: 1px solid #222; padding: 6px 12px;">Simulation</td>
                    <td style="border-bottom: 1px solid #222; padding: 6px 12px;"><strong>0.161 (29.0%)</strong></td>
                  </tr>
                  <tr>
                    <td style="border-bottom: 2px solid #222; padding: 6px 12px;">Backpropagation</td>
                    <td style="border-bottom: 2px solid #222; padding: 6px 12px;">1e-4 (0.02%)</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </p>
          <br>
          <br>
        </div>
        <h3 class="title is-4">Sparse MCTD</h3>
        <div class="content has-text-justified">
          <p>
            <div style="text-align: center;">
              <img src="static/images/smctd_overview.png" alt="Sparse MCTD Overview" style="width: 90%; height: auto;">
            </div>
            <br>
            Through the parallelization of the tree search, we can optimize the overhead on the sequential search. However, another fundamental inefficiency of MCTD is the iterative denoising process of diffusion model, which is computationally intensive.
            To address this, we proposed the Sparse MCTD (S-MCTD), which reduces the rollout length through trajectory coarsening, $\mathbf{x}'=[x_1, x_{H+1}, x_{2H+1}, $$\dots]$ where $H$ is the coarsening factor.
            Similar to the parallelism degree, too much coarsening can cause the information loss, we empirically found the optimal coarsening factor $H=5$.
            Interestingly, this coarsening process is not just improving the efficiency on denoising, but also reducing the search space by reducing the number of subplans as:
            $$
            C_{\text{S-MCTD}} = \mathcal{O}\left(N_{\text{child}}^{S/H} \cdot C_{\text{coarse}}\right),
            $$
            where $C_{\text{coarse}}$ is the denoising cost of the coarse trajectory.
            We observe that computational efficiency improves exponentially with the interval size $H$.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Fast-MCTD -->

<!-- Experiment results -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experimental Results</h2>
        <div class="content has-text-justified">
          <p>
            We evaluate the performance of Fast-MCTD on a variety of tasks, including long-horizon maze, robot arm manipulation, and partially observable & visual long-horizon maze tasks.
            While MCTD shows better performance than other baselines, the required time to generate plans from MCTD is generally much longer than other baselines.
            On the other hand, Fast-MCTD shows comparable performances to MCTD while achieving huge speedups.
            For instance, for PointMaze and AntMaze Giant tasks, Fast-MCTD achieves 100x and 80x speedup over MCTD while maintaining the similar performance.
            <br>
            <br>
            Especially, on Visual Maze large tasks, Fast-MCTD outperforms MCTD through the higher-level planning by improving the long-term planning generation quality.
            <br>
            <br>
            <img src="static/images/maze-results.png" alt="Experiment Results" style="width: 100%; height: auto;">
            <br>
            <img src="static/images/cube-results.png" alt="Experiment Results" style="width: 100%; height: auto;">
            <br>
            <img src="static/images/vmaze-results.png" alt="Experiment Results" style="width: 100%; height: auto;">
            <br>
          </p>
        </div>
        <h3 class="title is-4">Ablation Study</h3>
        <div class="content has-text-justified">
          <p>
            We conducted an ablation study to understand the contribution of each component of Fast-MCTD.
            <br>
            <br>
            <figure style="text-align: center;">
              <img src="static/images/ras_ablation.png" alt="Ablation Study" style="width: 100%; height: auto;">
              <figcaption style="margin-top: 8px; font-size: 1em; color: #555;">Ablation Study on Redundancy-Aware Selection</figcaption>
            </figure>
            The redundancy awareness (sequential selection) ablation study is shown in Table 5, we can see that the redundancy awareness is important to improve the efficiency on the long-horizon planning tasks.
            For the hyperparameter $w$ on our modified node selection policy, we found that if $w$ is not $0$ (considering the other concurrent rollouts), it's effect on the model performance is not significant. 
            <br>
            <br>
            <figure style="text-align: center;">
              <img src="static/images/parallelism_jump_ablation.png" alt="Ablation Study" style="width: 100%; height: auto;">
              <figcaption style="margin-top: 8px; font-size: 1em; color: #555;">Ablation Study on Parallelism Degree and Higher-Level Interval</figcaption>
            </figure>
            We took another ablation studies on the parallelism degree and higher-level abstraction interval.
            For parallelism degree, we found that the efficiency is dramatically improved when it is increased from $1$.
            When it is very high (e.g., 200), the performance is slightly degraded, but it is not significant, which means the overhead on searching from the old tree statistics is minor compared to the benefit from the parallelism.
            For the higher-level abstraction interval, we found the performance is drastically decreased when the interval is too large (e.g., 30), while the efficiency is saturated at 10.
            It is because the information loss of the coarse trajectory is too large to generate the good subplans.
          </p>
      </div>
    </div>
  </div>
</section>
<!-- End Experiment results -->

<!-- paper conclusion -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          <p>
            We introduced Fast Monte Carlo Tree Diffusion (Fast-MCTD), a scalable diffusion-based planning algorithm that resolves the planning horizon dilemma inherent to MCTD. By combining parallelized tree search (P-MCTD) with sparse sub-trajectory abstraction (S-MCTD), Fast-MCTD achieves significant inference-time speedups—up to 100× faster than MCTD in some tasks, while maintaining or exceeding performance across challenging long-horizon tasks. We demonstrated its effectiveness in maze navigation, robotic manipulation, and visual planning benchmarks. These gains are enabled by algorithmic innovations such as search-aware parallel rollouts and coarse-to-fine diffusion over abstract plans. While Fast-MCTD alleviates core efficiency bottlenecks, further improvements may be possible by integrating adaptive sparsity or learning-based guidance selection. Our findings highlight that structured reasoning from test-time scalability and efficient inference process are not mutually exclusive, opening new avenues for fast, deliberative decision-making in high-dimensional domains.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper conclusion -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{yoon2025fast,
          title={Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse Planning},
          author={Yoon, Jaesik and Cho, Hyeonseo and Bengio, Yoshua and Ahn, Sungjin},
          journal={arXiv preprint arXiv:2506.09498},
          year={2025}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
